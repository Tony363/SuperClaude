# SuperClaude Agent Framework

## Core Concept
Task agents are specialized sub-agents for complex operations. Use `--delegate` for automatic selection or specify directly with `Task(agent-name)`.

## Quality-Driven Execution
Every Task output gets a quality score (0-100):
- **90-100**: Production-ready â†’ Accept
- **70-89**: Acceptable â†’ Review notes
- **<70**: Needs improvement â†’ Auto-iterate

## Agent Quick Reference

See **TOOLS.md** for complete agent list and selection guide.

### Most Used Agents
- **general-purpose**: Unknown scope, exploration
- **root-cause-analyst**: Debugging, error investigation
- **refactoring-expert**: Code improvements, cleanup
- **quality-engineer**: Test coverage, quality metrics
- **technical-writer**: Documentation generation

## Extended Agent Library

For specialized needs beyond the 15 core agents:

### ðŸ“š 100+ Production-Ready Agents
- **Location**: `Agents/Extended/` directory
- **Organization**: 10 categories covering all development domains
- **Documentation**: See `AGENTS_EXTENDED.md` for quick discovery
- **Usage**: Same Task() interface, just specify path

### When to Use Extended Agents
- **Core agents** (15): Daily tasks, quick access, general purpose
- **Extended agents** (100+): Specialized expertise, specific technologies

### Quick Access Examples
```bash
# Core agent (simplified path)
Task(refactoring-expert)

# Extended agent (category path)
Task(Extended/02-language-specialists/rust-engineer)
Task(Extended/03-infrastructure/kubernetes-specialist)
```

### Popular Extended Categories
- `02-language-specialists/`: TypeScript, Rust, Go, Python experts
- `03-infrastructure/`: K8s, Terraform, Cloud, DevOps
- `05-data-ai/`: ML, LLM, Data Engineering
- `07-specialized-domains/`: Blockchain, IoT, FinTech

See **AGENTS_EXTENDED.md** for complete category guide and agent discovery.

## Context Package
Every delegation includes:
```yaml
context:
  goal: "What to achieve"
  constraints: ["limits", "requirements"]
  prior_work: {previous results}
  quality_criteria: {min_score: 70}
```

## Iteration Pattern
```
1. Delegate â†’ Task(agent, context)
2. Evaluate â†’ score = quality(output)  
3. Iterate â†’ if score < 70: retry with feedback
4. Accept â†’ when score â‰¥ 70
```

## Best Practices

### DO
- âœ… Always evaluate quality scores
- âœ… Preserve context across iterations
- âœ… Use specialist agents over general-purpose
- âœ… Let quality drive iterations

### DON'T
- âŒ Accept low-quality outputs
- âŒ Lose context between delegations
- âŒ Exceed iteration limits without permission

## Integration with Flags

| Flag | Effect on Agents |
|------|------------------|
| `--delegate` | Auto-select best agent |
| `--loop [n]` | Set max iterations |
| `--think [1-3]` | Analysis depth |
| `--safe-mode` | Conservative execution |

## Example Workflow

```bash
# Complex debugging
--think 2 --delegate
â†’ Uses root-cause-analyst
â†’ Quality: 65/100
â†’ Auto-iterates with feedback
â†’ Quality: 88/100 âœ…

# Refactoring with safety
--delegate --safe-mode --loop 5
â†’ Uses refactoring-expert
â†’ Maximum validation
â†’ Up to 5 iterations
```