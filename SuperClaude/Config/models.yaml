# SuperClaude Framework Model Configuration
# Version: 6.0.0-alpha

models:
  # OpenAI Models
  gpt-5:
    provider: openai
    context_window: 400000
    max_output: 50000
    supports_thinking: true
    priority: 1
    capabilities:
      - deep-reasoning
      - planning
      - consensus
    fallback: claude-opus-4.1

  gpt-4.1:
    provider: openai
    context_window: 1000000
    max_output: 32000
    supports_thinking: false
    priority: 3
    capabilities:
      - long-context
      - analysis
    fallback: gpt-4o

  gpt-4o:
    provider: openai
    context_window: 128000
    max_output: 16000
    supports_thinking: false
    priority: 4
    capabilities:
      - standard
      - fast
    fallback: gpt-4o-mini

  gpt-4o-mini:
    provider: openai
    context_window: 128000
    max_output: 16000
    supports_thinking: false
    priority: 5
    capabilities:
      - quick
      - lightweight
    fallback: null

  # Anthropic Models
  claude-opus-4.1:
    provider: anthropic
    context_window: 200000
    max_output: 32000
    supports_thinking: false
    priority: 2
    capabilities:
      - reasoning
      - validation
      - fallback
    fallback: null

  # Google Models
  gemini-2.5-pro:
    provider: google
    context_window: 2000000
    max_output: 50000
    supports_thinking: true
    priority: 1
    capabilities:
      - ultra-long-context
      - bulk-analysis
      - extended-context
    fallback: gpt-4.1

  # X.AI Models
  grok-4:
    provider: xai
    context_window: 256000
    max_output: 32000
    supports_thinking: true
    priority: 2
    capabilities:
      - code-analysis
      - reasoning
    fallback: grok-code-fast-1

  grok-code-fast-1:
    provider: xai
    context_window: 128000
    max_output: 16000
    supports_thinking: false
    priority: 3
    capabilities:
      - fast-code-analysis
      - quick-iteration
    fallback: gpt-4o

# Routing Configuration
routing:
  thresholds:
    standard_context: 400000
    long_context: 400000
    ultra_context: 1000000

  strategies:
    deep_thinking:
      primary: [gpt-5, gemini-2.5-pro]
      fallback: claude-opus-4.1
      token_budget: 50000

    consensus:
      ensemble: [gpt-5, claude-opus-4.1, gpt-4.1]
      quorum: 2
      token_budget_per_model: 30000

    long_context:
      primary: gemini-2.5-pro
      fallback: [gpt-4.1, gpt-5]
      auto_trigger_threshold: 400000

    fast_iteration:
      primary: grok-code-fast-1
      fallback: gpt-4o-mini
      token_budget: 5000

# Provider Configuration
providers:
  openai:
    api_key_env: OPENAI_API_KEY
    base_url: https://api.openai.com/v1
    rate_limit: 10000
    timeout: 600

  anthropic:
    api_key_env: ANTHROPIC_API_KEY
    base_url: https://api.anthropic.com/v1
    rate_limit: 5000
    timeout: 600

  google:
    api_key_env: GOOGLE_API_KEY
    base_url: https://generativelanguage.googleapis.com
    rate_limit: 5000
    timeout: 900

  xai:
    api_key_env: XAI_API_KEY
    base_url: https://api.x.ai/v1
    rate_limit: 5000
    timeout: 600